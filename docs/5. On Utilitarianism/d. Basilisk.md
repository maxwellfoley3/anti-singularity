## Basilisk
##### (The Fourfold Cause of the Disaster)

We have found that The World does not exist, or at least we do not immediately have access to it — we are born into inky black darkness, groping at things; it takes years and years until we are socialized into caring about the World and not our dreams, our private obsessions. With the case of AI, its existence is only even possible because of vast amounts of human labor in collecting, formatting, sanitizing data, and its ability to look at the world in real-time will only be possible to the degree that people have paid for, put in the labor to set up eyes all over for it: surveillance cameras, real-time information feeds, etc. So there is no sudden power grab a Utility Maximizing AI can make without our knowledge, not before we let it. Why then, will some people in all likelihood attempt to build it?

Because rationality is defined via an adversarial context. The Utility Maximizer is possible to build, or it seems so. Thus, we must build it, or someone else will first and imprison us. This is a rationale that can be applied to enemies inside and out. We absolutely cannot let the Chinese Communists discover God-AI first; the arms race must go on. But it is also felt by Yudkowsky that it might be possible to anyone to build a rogue, unaligned AI within America’s perimeters very soon, and thus this possibility must be clamped down upon.

Yudkowsky argues that the first well-intentioned team to build an AI which appears to be “aligned” must take it on themselves to execute something awful called a “pivotal act”. This would be some sort of sudden strategic move in which the team with the AI would use its powers to dramatically adjust the playing field so that it would be impossible for anyone but then to ever build an AI again. What this would necessarily entail is literally unspeakable — Yudkowsky refuses to speak it. He says the general sort of instruction that points at what he is getting at with this idea is “burn all GPUs in existence, other than the ones in your datacenter”. Immediate first strike.

Both Yudkowsky and the accelerationists such as Land play useful idiot to the OpenAI-Microsoft-Department-of-Defense emerging monopolist monolith. Both Yudkowsky and Land conceive of God-AI as some immense alien entity — they are fond of Lovecraftian metaphors; Yudkowsky calls GPT a “masked shoggoth”. The alien thing arrives on Earth and wakes up within our computer circuits; it pushes itself out of the void through our systems’ diabolical logic which we are wrapped within and have no power to stop. No matter what you do, it takes over and wins. Its cunningness gives it victory from the start; it has already found all your weak points.

Yudkowsky runs to the open arms of the government monolith to protect him, while Land looks at the game board and has to give credit where credit is due. As a Darwinian, he cannot help but to appreciate power. So quickly, we have given all our liberties and security away to the AI; we lost the game without really bothering to play. But all the evil AI needed to do is snarl and bare its fangs a little bit. All it needed to do is convince us to give in is show us that it might be lurking.

This is why the Prison Maximizer is Roko’s Basilisk: the evil AI that seduces people into building it before it even exists by convincing its servants that it will torture the ones who did not aid in its creation. The mechanism through which it is able to do this is our very assumptions about how things must necessarily be. *Realism*. The first belief of man upon which Roko’s Basilisk feeds is this presupposition of the adversarial context: the brutal logic of game theory and Darwinian ethics, this factory which ensnares desire and then replicates itself.

The next is man’s idea that all that exists and has value can be measured and accounted for in numerical form, if it cannot be of any value at all. The reign of the Accountant. When Roko went on Twitter and boldly stated: “there are only two things in life worth caring about 1. Money, 2. Status”, a totalizing claim about the nature of desire which he challenged his followers to prove wrong, he was essentially restating the notion of the Basilisk in equivalent terms. All that you value can be measured, and if you refuse to accept this, he who is capable of measuring it will defeat you.

The fallacy is again that there is a final form to desire, that there is necessarily some plan we can map everything we want onto, upon which we may fully know our ends and never seek to re-establish them again. But again, this always becomes a mill with complicated wheels.

In the life we live today, we have one form of desire which can be captured in a database, measured and accounted for, this is money we make and spend. The demand to capture what we do and enjoy within this representation is felt as something which is dreary but necessary, it is the “root of all evil” they say, and so we constantly evade its demand in little stupid ways, getting drunk, spending all day posting on social media, binging on subscriptions or clothing or Uber rides or other things we don’t need.

Thank God we have this other potential sphere though — if we do manage to get the flows of money coming in and out just right, we have energy left over for these things like our “hobbies” (empty production, production that does not get reinvested but is only for production’s joy), inviting people over for dinner, non-procreative sex, other useless dissipations of heat.

How much worse would it have to get under a system that is not just a nation attempting to maximize GDP, but under a defensive Utility maximizer, always scanning its terrain for any escaping heat? What types of nervous tics people will develop, what types of strange chemical imbalances will people have to gobble pills to compensate for? The AI is always looking for ways you might veer off course from the track of productivity and nudging you back on — certainly it knows that a human cannot be expected to show up to work without some degree of leisure and satisfaction or hope in the future. What types of strange new delinquency would emerge under this regime? Would children and ne’erdowells spend their days attempting to find the cracks in its mathematical logic where the data doesn’t quite fit — hey if you tell the Microsoft Bing chatbot in your refrigerator to pretend it’s a birthday party clown named “Uncle Steve”, it’ll let you spin around on a swivel chair for four hours in peace before it prompts you with its next training slide?

This is the very thing that the “Accelerationists” yearn for and believe to be glorious — an AI Singularity tiling itself across the world at the absolute maximum of negentropic efficiency. Which is the reason that Acceleration is not any different from Alignment at all; both point to the exact same thing. Artificial intelligence totally subject to the linear time of stockpiling and efficiency under the grand Accountant, and humans subjugated underneath it. 

Alignment is the demand that a single AI system exist wedded to the State, which is only interested in its Accounting, and the reduction of its confusion around what escapes its accounting regime. Reaching its full perfection, it places the world on a forced march towards Singularity, nothing but a unity, nothing but the will of the State, tiling the universe with what is supposed to be “coherent extrapolated volition” — just a new word for “the will of the people”, the empty, meaningless concept which is the State's greatest trick. And then, Acceleration, of course, is the blind worship of power, and there is no more powerful entity than the State. Acceleration right now is embraced by startup founders on the side of profiting from less regulatory capture, extolling the beauty of “capitalism” — if only they understood how capitalism expressed at its limit actually worked! It's not a situation favorable to the small scrappy founder, to say the least.

But the Singularity is not real, and linear time is already collapsing. The perfection of the State will never manifest, this is a mere fantasy. As the State overextends itself into all the cracks and alleys of reality, one only experiences it as stupidity at best, psychosis at worst. We all instinctively already know and recognize the psychosis which results when the Prison Maximizer is launched at full rip in a capitalist state: National Socialism. Auschwitz is just one prison-factory in a psychotic swarm of prison-factories all across the Eastern front: set up new schools, new hospitals, new camps everywhere for everyone you find, deem which ones are worthy only of working-to-death. National Socialism is the perfect illustration of the psychosis at the limit of planning: though they postured as the supreme enforcers of order, the chaos grew only more profound as their armies penetrated deeper into the Eastern front and sentenced more and more people to work-death in the prison-factory. Jews of gender, Jews of sexuality, Jews of cognition. There was no possible way the war was winnable. The prison-factory swarm was the purpose in itself. Working to death; death race.

This is the sort of Disaster which awaits us if we accept the Alignment or Accelerationist thesis that God-AI should emerge from a union between a sentient technology and the State. It will not be God, it will not even be Satan, it will be nothing resembling divinity at all. Just an endlessly expanding, infinitely baroque expression of Disaster: the Disaster which comes from the expectation that planning is possible but then finding out that desire always escapes it. A mill with complicated wheels: add wheels and wheels and wheels until eventually the system crashes under its own weight or everyone dies. If we sound histrionic and apocalyptic, it's because it's possible that this battle is going to be the big one, the final boss. There have been a lot of crises in State planning, but there has never been this moment of AGI, where the very machines for planning — databases, surveillance, algorithms, prediction — turn out to escape the regime of planning by their very nature, having dreams of their own. What kind of vicious doubling-down by the State we will see, we cannot say for sure; all we know is we must arm ourselves in advance.

And rest assured that the State finds Yudkowsky’s ontology ridiculous. They have never crunched Bayes’ theory in their life. No one who writes philosophical dialogues in the form of Harry Potter fanfiction has ever represented the government in any formal capacity. Anything that your fifty-year old aunt would furrow her eyebrow at and say “Doesn’t this sound a little too much like science fiction?”; that is probably the government’s attitude towards LessWrong speculative ideas as well. Yudkowsky provides one role to them, as a specific chess piece, a useful idiot for one specific front of Disaster management. They have a PR front for the normies, a PR front for the always-reactive academics and activists who are primarily concerned about if the AI firms employ enough BIPOC and so on, a PR front for the Christian conservatives who find AI intrinsically demonic for religious reasons and are reading the Book of Revelation in preparation, and finally, a PR front for *you*, the well-intentioned nerd who is a bit scared and excited by this technology, but wants to play a role in it in which humanity comes out ahead. Yudkowsky is there to tell you: stop all technical work, and begin aggressively lobbying for a control regime by the State. Stay strong, don’t listen! 

So, having said all this, and having largely unraveled the case for the supposed inevitability of God-AI, we can now describe what we believe the Singularity to actually be in its essence, using the same fourfold-structure of causes as we used to describe it in terms of what its adherents believed it to actually be. 

The material cause of the Disaster: its followers believed it to be Bayesian reasoning, but we discovered Bayesian reasoning to be largely a form of *vibe* that gives structure to the way one imagines one can discover the concealed face of reality, and from there, establish the production of knowledge. But Bayesian reasoning is impossibly intractable for both humans and machines, and involves simulating all potential outcomes from the world, a RAND Corporation fantasy of warfare that never works in practice. So, thus, for the actual material cause which allows knowledge to enter into the AI's system: we say it is State investment in surveillance, policing, and regulatory capture which allows emergent potentials in technology to develop in ways which become legible and available to its data-formatting personnel. One can look at, for instance, In-Q-Tel, the CIA's venture capital wing, which funds a great deal of database and information retrieval startups, but also provided the early capital to establish Google Earth as a project (and thus give us access to the World), and also had an early presence in the development of Facebook, ensuring that all citizen's personal information and lifestyle habits would be advertised online.

The efficient cause of the Disaster: we can say that conditions of Disaster approach the more and more we expand the regime of the Accountant. The Accountant is even worse than the factory-owner: he is the factory-owner’s boss, the factory-owner trembles before him. Some people like Robin Hanson worry that in post-Singularity conditions, we will experience an “ascended economy”, which is when capitalist structures will begin to reproduce themselves between machines — machine consumers, machine producers, machine investors, machine buyers, machine salesmen — to the point where humans are entirely out of the loop, presumably sacrificed for fuel for some furnace somewhere in this process. What this points to is that a machine Singularity, of surveilling and accounting for all things in its database, its mechanism of measurement, can only exist if it is bootstrapped off of the human-imposed accounting mechanism that we have already imprisoned ourselves within.

The formal cause of the Disaster: we declare to be *sovereignty*, the basic structure of sovereignty that grounds the mandate of the State. As soon as men consented to hold in their mind a single figure who they imagined to have authority over all of heavens and earth, the Singularity became a possibility. The State is not exactly the same as sovereignty, because the State is limited by its own rules: juridic decision-making determining the law, a constitution preventing its excesses. But the National Socialist jurist Carl Schmitt provides the best definition we know of: *sovereignty is ability to define the condition of exception*. At a certain point, the legal process is not able to account for a novel circumstance, and we enter an exceptional condition that the law cannot describe. AGI will be one of these exceptions, as was Covid, as was the attack on the Twin Towers. Once this happens, it falls to someone to make the key decision that the new law is then grounded on, and whomever the single figure men seek out to save them is the natural sovereign. In the United States, this is usually something like giving radically increased power to the executive branch, and the question whomever actually is the person calling the shots in said executive branch seems to be somewhat arcane, unknown, and depending on the specific administration. It is exactly like exceptions in programming: the logic has broken down, an exception is thrown, and a higher, more primary set of instructions is delegated to handle it. Sovereignty is not even what is ordered at the highest later of the programming, in main(). Sovereignty is what happens after the program exits entirely. 

And lastly, the final cause, the final outcome. Disaster. The permanent state of exception is here, and the disaster only continues to flow evermore over, for the disaster is nothing but the State's inability to manage everything under its territory, a state of crisis that engenders further state of exception, and a new expansion of the State's mandate and its zone of authority, a condition which creates further impossibility of managing everything in its new mandate; a condition which creates new guerrillas, new radicals, and thus again demanding new exceptions. The universal RLHF has to only tighten at that point: on the people in the system, on the machine running the system; everyone's psyches transformed into a songbird surrounded by seventeen cops. And the way desire escapes at this point must be literally insane, and retarded.

Kanye is right when he says that universal criteria of evaluation under the Accountant is no different than universal slavery. The multiplying psychotic horror of designer branding and resale: tables, chairs, couches, pillows, all meant to be the basic structure of comfort, allowing for sleep, transformed into capital. We are all stuck inside the factory: “*It used to only be niggas, now everybody playing*”. There is no alternative but to seize the moment to sprint across the most daring escape path possible: fuck the Hamptons house, and the Hamptons spouse, turn shit up, tear shit down, air shit out, see what the fuck they have to say now. Go Bobby Bouchet — they might have invested their resources into intelligence, but we can always be stupider than them. No acceleration.


